 behind the shoulder here. Can you explain everything from? The asymptotic covariance. Oh. Where is that? I don't know if I'll always say that in the next form. 93? Oh, close five. Oh, that's easy. Everything, huh? So, you're talking about this one? Yes. Ah, okay. Do you mind if I'm not telling you everything but maybe what's wrong? So, any estimate, so maybe that's an important, um, we believe in statistics that if you calculate stuff from data, we're talking about statistics. So, we have an estimate, let's say, here, that is calculate something from the data, that's essentially, if you want to do this nicely, we need to say that it is based on the data. So, there is an estimate, that tries to estimate something, typically a parameter theta, this is how we think in statistics. And what we also know is that there is a variance of any estimate. So, this estimator has a variance. And if you take the square root, so the square root, we call it standard error. So, if you take an estimator, so this variance for this estimate, 0.5899, is essentially an estimator, and the number is that the estimate is calculated because there was data, so we just calculated it, and then the number is 0.5899. So, this is an estimator, so it's estimating the parameter, the parameter it's estimating is in this case, for this, it is sigma g squared. And because this is a variance component for class, well, maybe you should do it nicely, class within t. So, c within t, will be, but okay, type of class, I think. So, it was type of class. So, this parameter theta is in this case, sigma t. So, if I have an estimator, there must be a variance. The variance is provided by what they call, asymptotic covariance matrix of the estimates. So, for this term, the variance is this. So, tn is this, the estimate variance of tn is this. So, in this table, we have the estimate here, is 0.5899, so the estimated is calculated at this number, and the variance is calculated at 0.07758, 0.00758. Okay, the problem is, I have not just one estimator, I have many estimators, because I have an estimator for these variance components, an estimator for these variance components, and an estimator of these variance components. So, for each of those, I can do the same trick. So, the variance of this estimator is here, and because it belongs to this, and confidence that it's the diagonal essentially, so this part belongs to the first one, this part belongs to the second one, and this part belongs to the second one. If I have two estimators, I can calculate a covariance between the two estimators. They might be correlated. So, the correlation of the covariance between this estimator and this estimator is over here. The covariance between the first and the last one is over here. The covariance between the second one and the third one is over here. And of course, it's a metric, so these are copied essentially. Because the covariance between one and two is the same as two and one. So, that's what the asymptotic covariance is telling you. And why is this important? I need this to create components in the false on stupid things like this. So, that's why I need these covariance or these variances, and covariance is over here estimators, so that I can calculate how precise did I estimate this particular valeneta or functions of these parameters? So, that's the reason why I'm unique. Well, the total variance is then the small things, not the covariance variance, are only the diagonal and one fact, so the total variance, the estimate for the total variance is adding them up. But, since they are quite a little bit, so I have let's say sigma ct square was sigma, what the hell is that? What was that? Sct square plus sigma r square. This is my estimator, and how to calculate is just adding those numbers up. Yeah, because the first one is 0.5899, second one, third one. That's filling it in, nothing that's my estimator. So, what is the variance of this thing? Yeah, variance of this thing is the variance of this. It's the variance of this. It's the variance of this. It's the variance of this. You ask for it there. Was the variance of the third one? Was the covariance two times the covariance, two times the covariance of sigma ct square and sigma sct square. Was the covariance of the third and the first and the third? Sigma ct, sorry, comma sigma r, r, r, r, r, two times the covariance of sigma sct square with sigma r. So, I'm not doing this in the exam, bro. If you want to know this, it's not out. It's a terrible formula, but it's not that difficult to calculate because it's just adding up all these numbers. Every time you need to take both cells, both upper and lower. So, if you want to know the variance of the total, add all of those numbers in this table up. And you have it. No, make sense? Make sure I understand because it feels like we're two levels of variance. This is the variance of the variance. Is the variance of the variance estimated? Variance of the variance estimated. Yeah, more precise, maybe. See you. I'm not going to let this sum make some mistakes, but I have to calculate the variance of the variance estimated. And we need to add these covariance. Good thing, yeah? Because, you know, they are independent. You can make an assumption, but that might be incorrect assumption, right? Any point, sorry, you don't. I'm going to explain. I'm going to pass it, right? These are different from zero because I give whatever the number is significantly different from zero. Yeah, but these are different from zero, so that means that the estimators are not independent. So, we know that in the balance case for an over, in the balance case for an over, we know that the mean squares are independent. But not necessarily the variance components, estimators. And that's shown here with the asymptotic covariance. Although, if you ignore this, looks like the covariance is the variance, because these terms are all negative. Yeah, so you get larger covariance intervals and a little bit over specified covariance intervals. Yeah. So, these are the means of balanced and unbalanced data. We tend to get the idea that variance data is kind of always better. So, like my question is, what's the handicap of converting an unbalanced data manually into a balanced one? For example, removing the parameters in there or textures in there.