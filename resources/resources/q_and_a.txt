 is in fact, first of all, is that possible? That one level is significant, but it's washouts. Yeah, sure, tell me. And secondly, if I do that, is that allowed? Is it still, is it truly significant? Or like, am I just going to get an average when I see the... Oh, you tell me. You have to die to some of this, did you? Is the average class value, yes? Or class one, or level one, your levels? So this is a value, another value. And this is a little bit of the variability that you see. There are many of those, and only one deviating. Could be that the overall test says I don't see anything. Not strong enough to actually demonstrate that the F test in your know-what table is significant. P value of 0.06. That's just about five percent. And a lot of the researchers are asking you get it lower, yeah? But this would be a situation that's not being tough. But if you see this, not sure what you believe. Do you believe there is really difference between classes? Or do you believe there is a recording issue here? Or if I have hundreds of those, very close to each other, and one deviates, I would say what happened in that class? And try to find out why this is so different. So it seems like we're almost saying that there's enough classes that they become a factor in themselves. So there's enough classes to essentially say you have one particular outcome outlier. Not strong enough to affect my F test to be rejecting the neural path of this data and no differences between groups. But of course, you always have to look at plots there to see whether or not you have to check your normalities. So if you would do a kind of a residual analysis, you will probably find some outlier. You have some outliers in the residual. You want to check up on those and say, hey, what's happening here? Is this correct? Is it not correct? How does this affect my conclusion? So you want to do a sensitivity analysis included, excluded, ask the question if C of the answers are remain the same or whether the answers are different than any have to make a decision in the end. And I would recommend making a conservative decision. I'm not trying to claim something that is actually based on an outlier. I was wondering about the lecture notice because we got a lot of lecture notice about the nova, but the chapter is about the neural model. The neural lecture notice on the mixed models. They're not finished yet. Are we pulled underneath the mix? Not before the A-sad. That's nice. So I think if you look at the, I certainly would like to write and finalize these lecture notes as well. They will follow the slides essentially. Although I do think that the linear mix model, the way that we build it up, we put much more theory on the ANOVA. And because the ANOVA essentially is a little bit cleaner to write the theory so that you can see a little bit how it works. And then essentially we say with the mixed models, we actually focusing a little bit more on how to look at things. And we do that. How can we model certain things, to reject these marginal models, things like that. And we focusing a little bit more on the data set. Because all the calculations are not identical, of course, with the ANOVA, but very simple. And so even if you would have the notes, I'm not sure it would be substantial amount of theory attached to this because that will be based on the ANOVA again. So it would be much more like OK. The model is the way you keep the model days, this is the code, this is the, and much more similar to the slides. So certainly I would like to finish it. But there's not much additional theory there, attached, except maybe for the reverence limit, but that's it, I would say, because it's follows the ANOVA essentially. Well, the maximum likelihood estimation for an ANOVA essentially. So question, I'm not thought of, but my name is David. I've very question about the picture set of my contradiction terms and the p-values. But it seems to me like if you put all the variables inside the NOVA model and then you check OK, this p-values once again take it out, the g-arts, looking at the results, and then both the only examples are significant. And then you stop, instead of like the AIC or the AIC, and then you really do get OK how well is my multi-linear added additional variables and I'm looking at p-values since, in a node model, you're concluding something with p-value and also constructing your model with p-value. With that seems strange, right? Well, yes and no. So I didn't discuss this, but there is literature on the AIC and the BIC. And essentially the AIC and the BIC can be reformulated as a likely racial test. So the p-value we use in the NOVA, they're not likely racial tests, they're based on F tests, using mean squares. But if it's a balanced NOVA, the estimations are very similar to the rebel estimates. Anyhow, yes, on these F tests and likely racial tests are not that much different. But the BIC and the AIC are essentially like racial tests at different significance levels. And these significant levels depend on the circle size. Yes, so the way that we are doing this, the AIC is essentially rejecting faster than a likely racial test. And the BIC is actually rejecting much less fast than a likely racial test that is used at often. No, I'm going to repeat it. And so let me get on about the data. So people have been warning, let's say, I've been using these values to build up my model in the past as well. And I was literature in that time of age saying, well, you shouldn't do that because you should use AIC. There's essentially a much better approach. And a later, I was different to say, wow, but the AIC, the BIC, I just like the racial test are in different significance levels. So I'm much different this time. So the whole area on that say model selection with B values and information criteria, well, let's say under development, and the views are changing over time, let's say. So sometimes I think that's a simply when you do a know-how. I don't think there is necessarily something wrong. We'll look at interactions, we'll look at the people and say, hey, it's not there, let's remove it. Don't do this for a million variables, yeah? So when we are looking for a million variables, I would not use B values. But when you have an example with three factors, there's a particular interaction to a metastatic to contribute to what is from the ANOVA tables, I'm happy to remove that. Would the AIC and the BIC give me exact any same results? Probably maybe that, depending on how significant the result is. If I am using BIC, I am using infinite, they will all conclude the same thing, removing it. Yeah, so the fence will indicate on how big this variable and disturb is in the model. There's no clear answer, yeah? I'm sorry for that. Now that's, I think, with a lot of the tools, yeah? It depends on what you use. You get sometimes different conclusions, yeah? We have to do this. This isn't real life. We wish that all of the tools will give you a jacket as I mentioned. That would make data analysis substantially simple. And you don't have to study it because we can automate it, yes? Yes, I was expecting it. We talked a lot about the theoretical mathematical kind of derivations of how we come up with these estimators. That really helps us understand why we're choosing the methods we're choosing for our computer. Once we have model builds and we're looking at the numbers, are you and we're analyzing? Are you ever coming back? Are you ever thinking back to the mathematical when you're looking at the number? Or is it just a... In rare cases? Yes. We set it up, then we better understand things. It kind of feels like a sandwich on the beginning at the end. And once we're done, then we can just look at the numbers. No, sorry. So in practice, I analyze a lot of data. And in practice, it's not always clear what is the right approach towards the selection, towards using a reach type of estimation technique actually used maximum likelihood, REMO, type 1, type 3. So when a sometimes you're not completely... This situation, I'm not completely sure what to do. So, let's try something out. And then look at the results. And sometimes you see, hey, this is crazy there. Two estimation techniques, as one of the examples in the slides, they give really different results, at least in the envelope I take. OK? Yeah, then you have to start making a decision. How can I make a decision? Well, I can do different things. I can go back to my mathematics and say, hey, maybe I can solve it from the mathematics and say, you can also say, OK, maybe I should simulate this type of data and see what happens. And then apply these different estimation techniques and see which one is closer to the truth. To validate essentially the choice you want to make for these data analytic questions. So there is a kind of a validation when there is doubt about certain choices. There is a validation aspect that is necessary. And I could sometimes be solved with the mathematics and sometimes be solved by looking at, well, other data sets or simulation sets, if you want, to see which approach is the right approach for this particular setting. I think that is part of the data science tool set. That's what they need to do in my opinion, is they want to become a good scientist, a scientist. Because it's very easy to put data in a software and look at the output. There's a nice big value level of five. I'm passing it over. Let's go next one. That's simple. Then we don't need a university education on it. We need to think what we are doing. I mean, you can understand what we are doing. And you need the math to understand this at least in this area of, let's say, data science. It might have been. You might, different. I'll see that in new calibration. OK. Is there any conclusions that you can draw when you look at and test value? Is there any? Oh, yes. I screen F values very often without looking at P values. F values bigger than four are usually not significant. I mean, the value itself, do you ever, when we're, like, from what I saw online, the format for reporting for those who have your F test value and the P value, at least blogs out of reading, sorry. But other than the fact that it's much greater than one or less than one, is there any thing that the actual value itself tells you? Yeah, certainly. So the larger the value, the stronger the effect is. So it's just a matter of ranking in that case. Like, it came actually say treatment three is two times stronger than treatment one. By using the F value? Yeah. No, I will not do that. OK. So I would know that it's at least, so if the F value is very large and no, there is a strong effect of treatment, if you want to understand what differences are between treatment I thought you were reaching out scale, you go to the outcome itself and want to see. You go, your outcome I hope makes clinical sense. Yeah, that's all you can do in clinical sense. Only is the Pisticle sense. Yeah. Anything? Yes. Look at the same type of people that ask for treatment. And you can consider, not sure. OK. So, what do you want to look at the standard that is in the details in that? Oh, I'm going to leave it on for the standard of the patient. OK. That's the question now. I think we'll be talking about the standard. The standard. I can talk about patient, residuals, and I talk about the standard of the residuals. No. Not really. So, if you are looking at the same assumption of normality, for instance, I think it doesn't really make a big difference to look at any of the standardised ones. But the standardised are much easy to evaluate outliers. Because the standardised, you know, anything beyond three or maybe four is really an outlier. Because under normality, this will not happen. Or unless you have millions of observations. Yeah. So that's why I would typically look at the standardised. For the evaluation of normality and heterogeneity issues, that's what really matters when you choose. But for outliers, it does. Yeah. Like, sense? Yes. Another one. Good. Great. Thanks. So, I'd like to ask you a few questions a bit. For the ethos, is there anything? The ethos tell you that their p-values don't. Because you say, like, if the value is four, then it's probably not sufficient for them, then that will also be because one of the p-values. So, all right. And I think they give the same information. Essentially. So that you can basically look at one of the two qualities. Yeah. And the p-value, the more likely, that it is a different. What is an excursion of people making the exam? It's a good question. I think I'm not sure, but the talk. Yeah, I don't always take questions. Somehow, many of you still step into it. Even if I've mentioned it during the class, you shouldn't do it. And then still you do. That's, I've wondered, I'm anything. And so, if I said that you need to use maximum like-lead estimation, or compare it, fix the fax models, then you forget. You use Rumble. It's crazy. Because I told you not to do this anymore. Yeah, but I made you do this. It's some stress or something like that. But so, and another thing is the exam is a little bit much. And this is on purpose. Yeah, I know you will complain at the end anyhow. But this is on purpose. Because I think if you look at the exam, you take the whole day. You will probably answer all the questions properly. Because it's every written down somewhere. You just need to find the right slide. And if you're trying to write it out, I think the only exam if you take a day, you'll have a 10. So, I- We take it in three hours. It tells me a little bit on how skilled you are in the topic. And because I think with a lot of effort, it's much more time. Don't think the exam is very complicated. Okay, that's my opinion. You might disagree with that as well, I guess. So, you need to make sure that you have prepared for answering. So, I think if you have really made all of the assignments that you prepare a little bit, suscoach for yourself so that you say, hey, if I need to calculate it, I have my suscoach ready. I just need to tweak it a little bit for this setting. I think that would speed up and help you prepare for the exam. You have to search for all your suscoach to where did I have this. A program and then you search for 10 minutes. Yeah, that is a disaster because you lose 10 minutes. You really can do it somewhere else. So, be prepared when you go to the exam. And of course, there are always an addition of few tricky questions but also really understood it. And also more or less understood. And it makes the difference between a very high grade and a somewhat lower class. I like tricky questions. Could we have a brief description of the differences between the models like a quick recap? What do you mean with a brief description of the different models? Like a nova mixed models. Can you describe a little bit the differences? There are three different models. There is the nova model. And then there is a nova model, which is ship arch for the mixed models. And in the mixed model, we like to talk about ship-expecific models and marginal models. The marginal models are in an essence, well, maybe there's not completely too. No, it's not. Let's not say. So there is a nova model. And a nova model typically has a lot of random effects in there where they don't have any, let's say, regression. There you will see there, like tongue. So it treats all of the factors that get the protocol. And you have the ship-expecific models. It's very similar to the nova, but now some are including, let's say, continuous variables into the model. And then I can play with the coefficients in this model by choosing them random. That's how you get these random lines or these random growth curves if you want. And it uses a lot of random statements, and not a lot of repeated statements. And then we have the marginal models that essentially says, OK, I just want to model the repeated statement of correlation over time. And I only want a mobile average thing. Not individual things. So this is how I classify the three types of models. And then within each of these, you can form many different things, depending on how many factors you include, not like the trajectories you want to model, etc. So within these classes, there are many different models. Choice essentially. So we have to have multiple arthets. If you have so, you have the type 3 arthets. The type 3 arthets, yes. And we have the type 3 arthets. We have them or not significant to call you 3 arthets. We will call them at the ones. From the model, for who you start to move, the model is the one that then would calculate the outcome. Yeah. I think that depends on your experience. Typically, I would be on the model by one. Because if you remove, let's say, turns out of the mullo, and you would rerun the mullo, P values could change. If the P values of the things that are really not significant are 9, let's point 9, 9. If I remove one term, it might drop a little bit, it will become 9, 7. And so you should be careful essentially when E values are not too close to the one and I will do the one by one. And then it's safer to do the one by one than to collectively take them out. Yes. With the Dirtridge and L-Hack, you showed the tables with various components and the small aspect of the future. Can you explain what's happening to the L-Hack? So can you help me with the slide, then? It's all row at the end. Okay. Yeah, it's in the middle of a maybe 92 version. Here? Can I have the right spot? Can I have a bit? Is the red there? The red tables? Uh-oh. I don't see any red tables, but... Oh, yeah, then it's... It's... In a tree way, you know, you can move it a little bit. Okay, so this is the way you know what I'm going to move it. Is that... oh, shall we just add something? Oh, yeah, it's... Oh, these red tables. Ah! Ah, okay. Ah, okay.